{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "    \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x']\n",
    "# model_names = ['yolov8x']\n",
    "models_ncc = ['faster_rcnn', 'swin', 'retinanet']\n",
    "f_data_path = '/home/user/2d/OUTPUTS_CVPR/{}_voc_test2'\n",
    "# coco_val_label_path = '/mnt/2d/YOLO-attack/datasets/coco2017/val/labels/val2017'\n",
    "# coco_train_label_path = '/mnt/2d/YOLO-attack/unet/labels/train2017'\n",
    "val_datasets = ['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing path: /home/user/2d/OUTPUTS_CVPR/voc_yolov8x.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_ncc:\n",
    "    # for val_dataset in val_datasets:\n",
    "    data_path = f_data_path.format(model_name)\n",
    "    print(f\"[INFO] Processing path: {data_path}\")\n",
    "    # imgs_base_path = os.path.join(data_path, 'base', \"images\", \"val\")\n",
    "    # labels_base_path = os.path.join(data_path, 'base', \"labels\", \"val\")\n",
    "    # os.makedirs(imgs_base_path, exist_ok=True)\n",
    "    # os.makedirs(labels_base_path, exist_ok=True)\n",
    "\n",
    "    imgs_attack_path = os.path.join(data_path, 'attack', 'images', 'val')\n",
    "    # labels_attack_path = os.path.join(data_path, 'attack', 'labels', 'val')\n",
    "    os.makedirs(imgs_attack_path, exist_ok=True)\n",
    "    # os.makedirs(labels_attack_path, exist_ok=True)\n",
    "\n",
    "    # Copy img base/attack vào folder mới\n",
    "    imgs_path = os.path.join(data_path, 'images_full', 'val')\n",
    "    for img_name in os.listdir(imgs_path):\n",
    "        img_real_path = os.path.join(imgs_path, img_name)\n",
    "        imgs = img_name.split('_')\n",
    "        if imgs[-1] == 'base':  #base img\n",
    "            continue\n",
    "            # img_base_path = os.path.join(imgs_base_path, imgs[0] + '.jpg')\n",
    "            # shutil.copy(img_real_path, img_base_path)\n",
    "        else:               #attack img\n",
    "            img_attack_path = os.path.join(imgs_attack_path, imgs[0] + \"_\" + imgs[1] + '.jpg')\n",
    "            shutil.copy(img_real_path, img_attack_path)\n",
    "\n",
    "    # Copy label vaf folder cua base/attack\n",
    "    # shutil.copytree(coco_val_label_path, labels_base_path, dirs_exist_ok=True)\n",
    "    # shutil.copytree(coco_val_label_path, labels_attack_path, dirs_exist_ok=True)\n",
    "    print(\"Done!\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference với model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2coco(xyxy, img_width, img_height): # [15.69, 406.17, 344.22, 627.35], 480, 640\n",
    "    x_min, y_min, x_max, y_max = xyxy\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    \n",
    "    x = (x_min + w/2) / img_width\n",
    "    y = (y_min + h/2) / img_height\n",
    "\n",
    "    w = w/img_width\n",
    "    h = h/img_height\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/2d/YOLOv8/datasets\n",
      "/home/user/2d/YOLOv8/datasets/attacked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_rcnn_coco_0.98  pred_label\t retina_voc_0.97\n",
      "faster_rcnn_voc_0.98   retina_coco_0.97  swin_coco_0.96\n"
     ]
    }
   ],
   "source": [
    "%cd datasets\n",
    "%cd attacked\n",
    "!ln -s /home/user/2d/OUTPUTS_CVPR/faster_rcnn_voc_0.98 faster_rcnn_voc_0.98\n",
    "!ln -s /home/user/2d/OUTPUTS_CVPR/retina_voc_0.97 retina_voc_0.97\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_datasets = ['attack']\n",
    "['yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x']\n",
    "models_ncc = ['swin']\n",
    "# f_data_path = '/home/user/2d/OUTPUTS_CVPR/{}_voc_test'\n",
    "img_path = \"/home/user/2d/OUTPUTS_CVPR/{}_voc_test2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing path: swin\n",
      "[INFO] Using yolov8n....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804/1804 [00:51<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8s....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804/1804 [00:48<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8m....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804/1804 [00:53<00:00, 34.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8l....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804/1804 [00:57<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8x....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804/1804 [01:00<00:00, 29.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE PATH]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_ncc in models_ncc:\n",
    "    print(f\"[INFO] Processing path: {model_ncc}\")\n",
    "    # img_attacked_path = os.path.join(img_path, \"attack/images/val\")\n",
    "    img_attacked_path = img_path.format(model_ncc)\n",
    "    for model_name in model_names:\n",
    "        print(f\"[INFO] Using {model_name}....\")\n",
    "        \n",
    "        model = YOLO(f\"/home/user/2d/YOLOv8/{model_name}.pt\")\n",
    "        model.conf = 0.5\n",
    "\n",
    "        imgs_list = [os.path.join(img_attacked_path, img_name) for img_name in os.listdir(img_attacked_path)]\n",
    "\n",
    "        for img in tqdm(imgs_list):\n",
    "            result = model.predict(img)[0]\n",
    "            h_img, w_img = result.orig_shape\n",
    "            boxes = result.boxes.data.cpu().numpy()\n",
    "            out = []\n",
    "            for box in boxes:\n",
    "                cls = int(box[-1])\n",
    "                xyxy = box[:4]\n",
    "                score = float(box[-2])\n",
    "                \n",
    "                x, y, w, h = yolo2coco(xyxy, w_img, h_img)\n",
    "                \n",
    "                out.append([cls, x, y, w, h, score])\n",
    "\n",
    "            # Save x, y, w, h format coco to txt file\n",
    "            img_name = os.path.split(result.path)[-1].split('.')[0]\n",
    "            # pred_label_path = os.path.join(os.path.dirname(coco_dict['path']), model_name, img_type)\n",
    "            pred_label_path = os.path.join(img_path, \"pred_label\", model_ncc, model_name)\n",
    "            if not os.path.exists(pred_label_path):\n",
    "                os.makedirs(pred_label_path, exist_ok=True)\n",
    "\n",
    "            np.savetxt(os.path.join(pred_label_path, img_name + '.txt'), out, fmt='%0.4f')\n",
    "\n",
    "\n",
    "    print(\"[DONE PATH]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to json (evaluate with cocoapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "import multiprocessing as mp\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/user/2d/OUTPUTS_CVPR/voc_test2/pred_label/{}\"\n",
    "img_path = \"/home/user/2d/OUTPUTS_CVPR/{}_voc_test2\"\n",
    "base_json_path = \"/home/user/2d/YOLOv8/datasets/coco2017/annotations/instances_val2017.json\"\n",
    "output_zip_path = \"result_attacked/voc_new\"\n",
    "os.makedirs(output_zip_path, exist_ok=True)\n",
    "\n",
    "coco_json = json.load(open(base_json_path))\n",
    "category_name_dict_coco = {v[\"name\"]: v[\"id\"] for v in coco_json[\"categories\"]}\n",
    "\n",
    "category_ids_dict_yolo = {\n",
    "  0: \"person\",\n",
    "  1: \"bicycle\",\n",
    "  2: \"car\",\n",
    "  3: \"motorcycle\",\n",
    "  4: \"airplane\",\n",
    "  5: \"bus\",\n",
    "  6: \"train\",\n",
    "  7: \"truck\",\n",
    "  8: \"boat\",\n",
    "  9: \"traffic light\",\n",
    "  10: \"fire hydrant\",\n",
    "  11: \"stop sign\",\n",
    "  12: \"parking meter\",\n",
    "  13: \"bench\",\n",
    "  14: \"bird\",\n",
    "  15: \"cat\",\n",
    "  16: \"dog\",\n",
    "  17: \"horse\",\n",
    "  18: \"sheep\",\n",
    "  19: \"cow\",\n",
    "  20: \"elephant\",\n",
    "  21: \"bear\",\n",
    "  22: \"zebra\",\n",
    "  23: \"giraffe\",\n",
    "  24: \"backpack\",\n",
    "  25: \"umbrella\",\n",
    "  26: \"handbag\",\n",
    "  27: \"tie\",\n",
    "  28: \"suitcase\",\n",
    "  29: \"frisbee\",\n",
    "  30: \"skis\",\n",
    "  31: \"snowboard\",\n",
    "  32: \"sports ball\",\n",
    "  33: \"kite\",\n",
    "  34: \"baseball bat\",\n",
    "  35: \"baseball glove\",\n",
    "  36: \"skateboard\",\n",
    "  37: \"surfboard\",\n",
    "  38: \"tennis racket\",\n",
    "  39: \"bottle\",\n",
    "  40: \"wine glass\",\n",
    "  41: \"cup\",\n",
    "  42: \"fork\",\n",
    "  43: \"knife\",\n",
    "  44: \"spoon\",\n",
    "  45: \"bowl\",\n",
    "  46: \"banana\",\n",
    "  47: \"apple\",\n",
    "  48: \"sandwich\",\n",
    "  49: \"orange\",\n",
    "  50: \"broccoli\",\n",
    "  51: \"carrot\",\n",
    "  52: \"hot dog\",\n",
    "  53: \"pizza\",\n",
    "  54: \"donut\",\n",
    "  55: \"cake\",\n",
    "  56: \"chair\",\n",
    "  57: \"couch\",\n",
    "  58: \"potted plant\",\n",
    "  59: \"bed\",\n",
    "  60: \"dining table\",\n",
    "  61: \"toilet\",\n",
    "  62: \"tv\",\n",
    "  63: \"laptop\",\n",
    "  64: \"mouse\",\n",
    "  65: \"remote\",\n",
    "  66: \"keyboard\",\n",
    "  67: \"cell phone\",\n",
    "  68: \"microwave\",\n",
    "  69: \"oven\",\n",
    "  70: \"toaster\",\n",
    "  71: \"sink\",\n",
    "  72: \"refrigerator\",\n",
    "  73: \"book\",\n",
    "  74: \"clock\",\n",
    "  75: \"vase\",\n",
    "  76: \"scissors\",\n",
    "  77: \"teddy bear\",\n",
    "  78: \"hair drier\",\n",
    "  79: \"toothbrush\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing path: /home/user/2d/OUTPUTS_CVPR/voc_test2/pred_label/faster_rcnn\n",
      "[INFO] Using yolov8n....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1215it [00:00, 16994.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8s....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1215it [00:00, 22108.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8m....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1215it [00:00, 21113.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8l....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1215it [00:00, 17622.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8x....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1215it [00:00, 18884.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing path: /home/user/2d/OUTPUTS_CVPR/voc_test2/pred_label/swin\n",
      "[INFO] Using yolov8n....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 27318.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8s....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 54465.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8m....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 72422.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8l....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 71765.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8x....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 68083.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing path: /home/user/2d/OUTPUTS_CVPR/voc_test2/pred_label/retinanet\n",
      "[INFO] Using yolov8n....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3595it [00:00, 22756.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8s....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3595it [00:00, 18469.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8m....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3595it [00:00, 15050.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8l....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3595it [00:00, 10912.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using yolov8x....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3595it [00:00, 15437.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_ncc in models_ncc:\n",
    "    base_path_ncc = base_path.format(model_ncc)\n",
    "    print(f\"[INFO] Processing path: {base_path_ncc}\")\n",
    "    for model_name in model_names:\n",
    "        print(f\"[INFO] Using {model_name}....\")\n",
    "        yolo_detect_txt_path = os.path.join(base_path_ncc, model_name)\n",
    "\n",
    "        image_dir = img_path.format(model_ncc)\n",
    "        \n",
    "        detect_json = []\n",
    "        total_annotation_count_pred = 0\n",
    "\n",
    "        for idx, image_name in tqdm(enumerate(os.listdir(image_dir))):\n",
    "            width, height = imagesize.get(os.path.join(image_dir, image_name))\n",
    "            if (os.path.exists(os.path.join(yolo_detect_txt_path, image_name.replace(\"jpg\", \"txt\"))) is False):\n",
    "                continue\n",
    "            \n",
    "            with open(os.path.join(yolo_detect_txt_path, image_name.replace(\"jpg\", \"txt\"))) as f:\n",
    "                    annotations = f.readlines()\n",
    "\n",
    "            for annotation in annotations:\n",
    "                annotation = annotation.strip().split(\" \")\n",
    "                bbox = [float(i) for i in annotation[1:]]\n",
    "                x1, y1, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "                score = float(bbox[4])\n",
    "                x1 = (x1 - w / 2) * width\n",
    "                y1 = (y1 - h / 2) * height\n",
    "                w = w * width\n",
    "                h = h * height\n",
    "                detect_json.append(\n",
    "                    {\n",
    "                        \"image_id\": os.path.splitext(image_name)[0],\n",
    "                        \"category_id\": category_name_dict_coco[\n",
    "                            category_ids_dict_yolo[int(float(annotation[0]))]\n",
    "                        ],\n",
    "                        \"bbox\": [x1, y1, w, h],\n",
    "                        # \"score\": float(annotation[5]),\n",
    "                        \"score\": score,\n",
    "                    }\n",
    "                )\n",
    "                total_annotation_count_pred += 1\n",
    "    \n",
    "\n",
    "        os.makedirs(os.path.join(output_zip_path, model_ncc, model_name), exist_ok=True)\n",
    "        with open(os.path.join(output_zip_path, model_ncc, model_name, \"detect_attack.json\"), \"w\") as f:\n",
    "            json.dump(detect_json, f)\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new label for gt voc (instance_val2017.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_coco_path = \"data/voc_coco\"\n",
    "# imgs_new_path = os.path.join(voc_coco_path, \"val\")\n",
    "# os.makedirs(imgs_new_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_info(annotation_root, extract_num_from_imgid=False):\n",
    "    path = annotation_root.findtext('path')\n",
    "    if path is None:\n",
    "        filename = annotation_root.findtext('filename')\n",
    "    else:\n",
    "        filename = os.path.basename(path)\n",
    "    img_name = os.path.basename(filename)\n",
    "    img_id = os.path.splitext(img_name)[0]\n",
    "    if extract_num_from_imgid and isinstance(img_id, str):\n",
    "        img_id = int(re.findall(r'\\d+', img_id)[0])\n",
    "\n",
    "    size = annotation_root.find('size')\n",
    "    width = int(size.findtext('width'))\n",
    "    height = int(size.findtext('height'))\n",
    "\n",
    "    image_info = {\n",
    "        'file_name': filename,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'id': img_id,\n",
    "        \"license\": 0,\n",
    "        \"flickr_url\": \"\",\n",
    "        \"coco_url\": \"\",\n",
    "        \"date_captured\": 0,\n",
    "    }\n",
    "    return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new label for gt coco (instance_val2017.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_json_path = \"/home/user/2d/mmdetection/data/coco/annotations/instances_val2017.json\"\n",
    "coco_json = json.load(open(base_json_path))\n",
    "category_idx_dict_coco = {v[\"name\"]: v[\"id\"] for v in coco_json[\"categories\"]}\n",
    "voc_to_coco = {\n",
    "    'aeroplane': 'airplane',\n",
    "    'bicycle': 'bicycle',\n",
    "    'bird': 'bird',\n",
    "    'boat': 'boat',\n",
    "    'bottle': 'bottle',\n",
    "    'bus': 'bus',\n",
    "    'car': 'car',\n",
    "    'cat': 'cat',\n",
    "    'chair': 'chair',\n",
    "    'cow': 'cow',\n",
    "    'diningtable': 'dining table',\n",
    "    'dog': 'dog',\n",
    "    'horse': 'horse',\n",
    "    'motorbike': 'motorcycle',\n",
    "    'person': 'person',\n",
    "    'pottedplant': 'potted plant',\n",
    "    'sheep': 'sheep',\n",
    "    'sofa': 'couch',\n",
    "    'train': 'train',\n",
    "    'tvmonitor': 'tv'\n",
    "}\n",
    "\n",
    "voc_ids_dict = {\n",
    "    0: 'aeroplane',\n",
    "    1: 'bicycle',\n",
    "    2: 'bird',\n",
    "    3: 'boat',\n",
    "    4: 'bottle',\n",
    "    5: 'bus',\n",
    "    6: 'car',\n",
    "    7: 'cat',\n",
    "    8: 'chair',\n",
    "    9: 'cow',\n",
    "    10: 'diningtable',\n",
    "    11: 'dog',\n",
    "    12: 'horse',\n",
    "    13: 'motorbike',\n",
    "    14: 'person',\n",
    "    15: 'pottedplant',\n",
    "    16: 'sheep',\n",
    "    17: 'sofa',\n",
    "    18: 'train',\n",
    "    19: 'tvmonitor',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3701"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/home/user/2d/OUTPUTS_CVPR/voc_yolov8x.pt/attack/images/val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/home/user/2d/OUTPUTS_CVPR/swin_voc_test2\"\n",
    "f = open('/home/user/2d/mmdetection/data/VOCdevkit/VOC2012/ImageSets/Main/new_val_swin_voc_test2.txt', 'w')\n",
    "for img_name in sorted(os.listdir(image_dir)):\n",
    "    f.write(os.path.splitext(img_name)[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [00:00, 14300.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130\n",
      "1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "yolo_txt_path = \"/home/user/2d/datasets/VOC/labels/val2012\"\n",
    "image_dir = \"/home/user/2d/OUTPUTS_CVPR/swin_voc_test2\"\n",
    "\n",
    "\n",
    "images_info = []\n",
    "annotations_coco = []\n",
    "total_annotation_count = 1\n",
    "total_annotation_count_gt = 0\n",
    "total_anno_file = 0\n",
    "\n",
    "for idx, image_name in tqdm(enumerate(os.listdir(image_dir))):\n",
    "    width, height = imagesize.get(os.path.join(image_dir, image_name))\n",
    "    images_info.append(\n",
    "        {\n",
    "            \"id\": os.path.splitext(image_name)[0],\n",
    "            \"file_name\": image_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"license\": 0,\n",
    "            \"flickr_url\": \"\",\n",
    "            \"coco_url\": \"\",\n",
    "            \"date_captured\": 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if (os.path.exists(os.path.join(yolo_txt_path, image_name.replace(\"jpg\", \"txt\"))) is False):\n",
    "            continue\n",
    "    \n",
    "    with open(os.path.join(yolo_txt_path, image_name.replace(\"jpg\", \"txt\"))) as f:\n",
    "        annotations = f.readlines()\n",
    "        total_anno_file += 1\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        # convert yolo bounding boxes to coco\n",
    "        annotation = annotation.strip().split(\" \")\n",
    "        \n",
    "        category_id_coco = category_idx_dict_coco[voc_to_coco[voc_ids_dict[int(annotation[0])]]]\n",
    "\n",
    "        bbox = [float(i) for i in annotation[1:5]]\n",
    "        x1, y1, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "        x1 = (x1 - w / 2) * width\n",
    "        y1 = (y1 - h / 2) * height\n",
    "        w = w * width\n",
    "        h = h * height\n",
    "        annotations_coco.append(\n",
    "            {\n",
    "                \"id\": total_annotation_count,\n",
    "                \"image_id\": os.path.splitext(image_name)[0],\n",
    "                \"category_id\": category_id_coco,\n",
    "                \"area\": w * h,\n",
    "                \"segmentation\": [],\n",
    "                \"bbox\": [x1, y1, w, h],\n",
    "                \"iscrowd\": 0,\n",
    "                \"attributes\": {\"occluded\": False},\n",
    "            }\n",
    "        )\n",
    "        total_annotation_count += 1\n",
    "        total_annotation_count_gt += 1\n",
    "coco_json[\"images\"] = images_info\n",
    "coco_json[\"annotations\"] = annotations_coco\n",
    "\n",
    "print(total_annotation_count_gt)\n",
    "print(total_anno_file)\n",
    "# os.makedirs(os.path.join(output_zip_path), exist_ok=True)\n",
    "with open(os.path.join(output_zip_path, \"instances_defaults_swin_voc_test2.json\"), \"w\") as f:\n",
    "    json.dump(coco_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "1804\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.1208\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.1705\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.1275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.0320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.0509\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.1453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.1206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.1347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.1348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.0329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.0602\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.1575\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "annType = \"bbox\"\n",
    "\n",
    "cocoGt = COCO(\"/home/user/2d/YOLOv8/result_attacked/voc_new/instances_defaults_swin_voc_test2.json\")\n",
    "cocoDt = cocoGt.loadRes(\"/home/user/2d/YOLOv8/result_attacked/voc_new/swin/yolov8m/detect_attack.json\")\n",
    "\n",
    "imgIds = sorted(cocoGt.getImgIds())\n",
    "print(len(imgIds))\n",
    "\n",
    "# running evaluation\n",
    "cocoEval = COCOeval(cocoGt, cocoDt, annType)\n",
    "cocoEval.params.imgIds = imgIds\n",
    "# cocoEval.params.catIds = [3]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
